{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb1610df-5525-4463-a881-6684f1636016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from pyspark.sql.functions import col, lit, current_timestamp\n",
    "\n",
    "catalog = \"dataquality\"\n",
    "schema = \"dq_demo\"\n",
    "base_path = f\"/Volumes/{catalog}/{schema}/dq_demo_volume\"\n",
    "\n",
    "pipeline_name = \"bev_hourly_pipeline\"\n",
    "\n",
    "# -----------------------\n",
    "# 1. 進捗取得\n",
    "# -----------------------\n",
    "state_df = spark.table(f\"{catalog}.{schema}.ingest_state\") \\\n",
    "    .where(col(\"pipeline_name\") == pipeline_name)\n",
    "\n",
    "last_ts = state_df.select(\"last_processed_hour\").collect()[0][0]\n",
    "next_hour = last_ts + timedelta(hours=1)\n",
    "\n",
    "mm_dd = next_hour.strftime(\"%m-%d\")\n",
    "hh = next_hour.strftime(\"%H\")\n",
    "\n",
    "input_path = f\"{base_path}/dt={mm_dd}/hr={hh}\"\n",
    "\n",
    "print(\"Processing hour:\", next_hour, input_path)\n",
    "\n",
    "# -----------------------\n",
    "# 2. ファイル読込\n",
    "# -----------------------\n",
    "bronze_df = (\n",
    "    spark.read\n",
    "      .json(input_path)\n",
    "      .withColumn(\"ingest_hour\", lit(next_hour))\n",
    "      .withColumn(\"ingested_at\", current_timestamp())\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 3. Bronze 書き込み\n",
    "# -----------------------\n",
    "bronze_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(f\"{catalog}.{schema}.bronze_bev_events\")\n",
    "\n",
    "# -----------------------\n",
    "# 4. state 更新\n",
    "# -----------------------\n",
    "spark.sql(f\"\"\"\n",
    "UPDATE {catalog}.{schema}.ingest_state\n",
    "SET last_processed_hour = TIMESTAMP '{next_hour}',\n",
    "    updated_at = current_timestamp()\n",
    "WHERE pipeline_name = '{pipeline_name}'\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
